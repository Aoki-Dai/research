{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e839eb8",
   "metadata": {},
   "source": [
    "## ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00dfc530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f949d23d",
   "metadata": {},
   "source": [
    "## 全テキストから名詞のみを抽出してWord2Vec用のコーパスを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ac471b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# ユーザー履歴のコーパスを作成\u001b[39;00m\n\u001b[32m     24\u001b[39m user_columns = [\u001b[33m'\u001b[39m\u001b[33mproject_name\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m user_corpus = create_corpus(\u001b[43mdf\u001b[49m, user_columns)\n\u001b[32m     27\u001b[39m プロジェクトカタログのコーパスを作成\n\u001b[32m     28\u001b[39m project_columns = [\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdesired_role\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# 全テキストから名詞のみを抽出してWord2Vec用のコーパスを作成\n",
    "def create_corpus(df, columns):\n",
    "    \"\"\"\n",
    "    DataFrameから指定列のテキストを抽出し、名詞のみのリストのリストを作成\n",
    "    \"\"\"\n",
    "    corpus = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        # 各行の指定列を結合\n",
    "        combined_text = ' '.join([str(row[col]) for col in columns if pd.notna(row[col])])\n",
    "        \n",
    "        # 形態素解析を実行\n",
    "        tokens = tokenizer_obj.tokenize(combined_text)\n",
    "        \n",
    "        # 名詞のみを抽出\n",
    "        words = [token.surface() for token in tokens if token.part_of_speech()[0] == '名詞']\n",
    "        \n",
    "        if words:  # 空でない場合のみ追加\n",
    "            corpus.append(words)\n",
    "    \n",
    "    return corpus\n",
    "\n",
    "# ユーザー履歴のコーパスを作成\n",
    "user_columns = ['project_name', 'description', 'role']\n",
    "user_corpus = create_corpus(df, user_columns)\n",
    "\n",
    "プロジェクトカタログのコーパスを作成\n",
    "project_columns = ['name', 'description', 'desired_role']\n",
    "project_corpus = create_corpus(project_df, project_columns)\n",
    "\n",
    "両方を結合\n",
    "corpus = user_corpus + project_corpus\n",
    "corpus = user_corpus\n",
    "\n",
    "print(f\"ユーザー職歴コーパス: {len(user_corpus)}件\")\n",
    "print(f\"プロジェクトカタログコーパス: {len(project_corpus)}件\")\n",
    "print(f\"結合コーパス: {len(corpus)}件\")\n",
    "\n",
    "print(\"\\n【ユーザー職歴】最初の2件のサンプル:\")\n",
    "for i, doc in enumerate(user_corpus[:2]):\n",
    "    print(f\"{i+1}: {doc[:10]}...\")\n",
    "\n",
    "print(\"\\n【プロジェクトカタログ】最初の2件のサンプル:\")\n",
    "for i, doc in enumerate(project_corpus[:2]):\n",
    "    print(f\"{i+1}: {doc[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419d00bd",
   "metadata": {},
   "source": [
    "## モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6b07da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "語彙数: 140語\n",
      "ベクトルの次元数: 100\n"
     ]
    }
   ],
   "source": [
    "# Word2Vecモデルの学習\n",
    "model = Word2Vec(\n",
    "    sentences=corpus,      # 学習データ\n",
    "    vector_size=100,       # ベクトルの次元数\n",
    "    window=5,              # コンテキストウィンドウのサイズ\n",
    "    min_count=1,           # 最小出現回数（これ以下の単語は無視）\n",
    "    # workers=4,             # 並列処理のワーカー数\n",
    "    sg=1,                  # 0: CBOW, 1: Skip-gram\n",
    "    epochs=100,             # エポック数\n",
    "    negative=5,            # ネガティブサンプリング数（Skip-gram使用時）\n",
    "    alpha=0.025,           # 初期学習率（デフォルト値）\n",
    "    min_alpha=0.0001,      # 最小学習率\n",
    "    seed=42                # 再現性のため\n",
    ")\n",
    "\n",
    "print(f\"語彙数: {len(model.wv)}語\")\n",
    "print(f\"ベクトルの次元数: {model.wv.vector_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6e1d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "語彙数: 140語\n",
      "\n",
      "総単語数: 18275\n",
      "ユニーク単語数: 140\n",
      "\n",
      "頻出単語 Top 20:\n",
      "  担当: 805回\n",
      "  開発: 799回\n",
      "  テスト: 470回\n",
      "  構築: 444回\n",
      "  設計: 412回\n",
      "  改善: 332回\n",
      "  クラウド: 282回\n",
      "  チーム: 282回\n",
      "  プロジェクト: 254回\n",
      "  UI: 222回\n",
      "  UX: 222回\n",
      "  エンジニア: 222回\n",
      "  レビュー: 211回\n",
      "  顧客: 211回\n",
      "  調整: 211回\n",
      "  実施: 208回\n",
      "  リファクタリング: 207回\n",
      "  既存: 204回\n",
      "  システム: 204回\n",
      "  要件: 202回\n"
     ]
    }
   ],
   "source": [
    "# 語彙数の確認\n",
    "print(f\"語彙数: {len(model.wv)}語\")\n",
    "\n",
    "# 頻出単語の確認\n",
    "all_words = [word for doc in corpus for word in doc]\n",
    "word_freq = Counter(all_words)\n",
    "print(f\"\\n総単語数: {len(all_words)}\")\n",
    "print(f\"ユニーク単語数: {len(word_freq)}\")\n",
    "print(\"\\n頻出単語 Top 20:\")\n",
    "for word, count in word_freq.most_common(20):\n",
    "    print(f\"  {word}: {count}回\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ec25e6",
   "metadata": {},
   "source": [
    "## モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01959c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "モデルを保存しました: word2vec_model.bin\n",
      "単語ベクトルを保存しました: word2vec_vectors.kv\n"
     ]
    }
   ],
   "source": [
    "model.save(\"../results/models/word2vec_model.bin\")\n",
    "print(\"モデルを保存しました: word2vec_model.bin\")\n",
    "\n",
    "# 単語ベクトルのみを保存（より軽量）\n",
    "model.wv.save(\"../results/models/word2vec_vectors.kv\")\n",
    "print(\"単語ベクトルを保存しました: word2vec_vectors.kv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c020868",
   "metadata": {},
   "source": [
    "## ベクトル化した単語の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5f5485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "単語: 開発\n",
      "ベクトル (最初の10次元): [-0.11796082 -0.16586249  0.15224838 -0.28193828 -0.20976922  0.284552\n",
      "  0.00346189  0.06835559  0.18295953 -0.16947858]\n",
      "ベクトルの形状: (100,)\n",
      "\n",
      "単語: システム\n",
      "ベクトル (最初の10次元): [-0.13215175 -0.12867358  0.18591525 -0.40815824  0.20622589  0.22197193\n",
      "  0.2578488   0.32634795 -0.13182755 -0.06729237]\n",
      "ベクトルの形状: (100,)\n",
      "\n",
      "単語: AWS\n",
      "ベクトル (最初の10次元): [-0.07182981 -0.24260373 -0.5322119   0.3196711   0.0406214  -0.30522817\n",
      " -0.19449857  0.36219177 -0.5959646   0.11270412]\n",
      "ベクトルの形状: (100,)\n",
      "\n",
      "単語: React\n",
      "ベクトル (最初の10次元): [-0.10373149  0.23902212 -0.3685489   0.33588377 -0.22443077  0.15456818\n",
      " -0.06230635  0.22421545 -0.06158894  0.61248684]\n",
      "ベクトルの形状: (100,)\n",
      "\n",
      "単語 'Python' は語彙に含まれていません\n"
     ]
    }
   ],
   "source": [
    "# 単語ベクトルの確認\n",
    "test_words = ['開発', 'システム', 'AWS', 'React', 'Python']\n",
    "\n",
    "for word in test_words:\n",
    "    if word in model.wv:\n",
    "        vector = model.wv[word]\n",
    "        print(f\"\\n単語: {word}\")\n",
    "        print(f\"ベクトル (最初の10次元): {vector[:10]}\")\n",
    "        print(f\"ベクトルの形状: {vector.shape}\")\n",
    "    else:\n",
    "        print(f\"\\n単語 '{word}' は語彙に含まれていません\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8519e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'AWS' に類似する単語:\n",
      "  主導: 0.5236\n",
      "  オンプレミス: 0.4971\n",
      "  環境: 0.4639\n",
      "  デプロイ: 0.4100\n",
      "  CD: 0.3938\n",
      "  CI: 0.3930\n",
      "  パイプライン: 0.3929\n",
      "  調査: 0.3826\n",
      "  課題: 0.3818\n",
      "  管理: 0.3804\n"
     ]
    }
   ],
   "source": [
    "# 類似単語の検索\n",
    "test_word = 'AWS'\n",
    "\n",
    "if test_word in model.wv:\n",
    "    similar_words = model.wv.most_similar(test_word, topn=10)\n",
    "    print(f\"\\n'{test_word}' に類似する単語:\")\n",
    "    for word, similarity in similar_words:\n",
    "        print(f\"  {word}: {similarity:.4f}\")\n",
    "else:\n",
    "    print(f\"単語 '{test_word}' は語彙に含まれていません\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dadaa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'リーダー' に類似する単語:\n",
      "  テスター: 0.6185\n",
      "  プログラマー: 0.5881\n",
      "  SE: 0.5686\n",
      "  SWE: 0.5564\n",
      "  PM: 0.5530\n",
      "  PG: 0.5228\n",
      "  インフラエンジニア: 0.4912\n",
      "  システムエンジニア: 0.4896\n",
      "  デザイナー: 0.4676\n",
      "  QA: 0.4140\n"
     ]
    }
   ],
   "source": [
    "# 類似単語の検索\n",
    "test_word = 'リーダー'\n",
    "\n",
    "if test_word in model.wv:\n",
    "    similar_words = model.wv.most_similar(test_word, topn=10)\n",
    "    print(f\"\\n'{test_word}' に類似する単語:\")\n",
    "    for word, similarity in similar_words:\n",
    "        print(f\"  {word}: {similarity:.4f}\")\n",
    "else:\n",
    "    print(f\"単語 '{test_word}' は語彙に含まれていません\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dec1f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "単語間の類似度:\n",
      "  AWS - Azure: どちらかの単語が語彙に含まれていません\n",
      "  React - Vue: 0.5326\n",
      "  Python - Java: どちらかの単語が語彙に含まれていません\n",
      "  開発 - 構築: 0.1938\n",
      "  プログラミング - 開発: 0.2018\n",
      "  プログラミング - 構築: 0.2672\n"
     ]
    }
   ],
   "source": [
    "# 単語間の類似度を計算\n",
    "word_pairs = [\n",
    "    ('AWS', 'Azure'),\n",
    "    ('React', 'Vue'),\n",
    "    ('Python', 'Java'),\n",
    "    ('開発', '構築'),\n",
    "    ('プログラミング', '開発'),\n",
    "    ('プログラミング', '構築'),\n",
    "]\n",
    "\n",
    "print(\"\\n単語間の類似度:\")\n",
    "for word1, word2 in word_pairs:\n",
    "    if word1 in model.wv and word2 in model.wv:\n",
    "        similarity = model.wv.similarity(word1, word2)\n",
    "        print(f\"  {word1} - {word2}: {similarity:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {word1} - {word2}: どちらかの単語が語彙に含まれていません\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3178c526",
   "metadata": {},
   "source": [
    "## 単語ベクトルをcsvに保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5f3d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "単語ベクトルをCSVに保存しました: data/external/word_vectors.csv\n",
      "形状: (140, 100)\n",
      "\n",
      "最初の5単語:\n",
      "           0         1         2         3         4         5         6   \\\n",
      "担当   0.253113  0.142081  0.107371 -0.036470  0.329581  0.090653 -0.131531   \n",
      "開発  -0.117961 -0.165862  0.152248 -0.281938 -0.209769  0.284552  0.003462   \n",
      "テスト  0.081841  0.038523  0.276648  0.032594 -0.001037  0.324496  0.165522   \n",
      "構築  -0.212445  0.108158 -0.231526 -0.123558  0.415946  0.014031 -0.121279   \n",
      "設計   0.455223  0.096547  0.037000  0.293948  0.272290  0.063192 -0.009637   \n",
      "\n",
      "           7         8         9   ...        90        91        92  \\\n",
      "担当  -0.060467 -0.106479 -0.214658  ...  0.016891  0.026645  0.222169   \n",
      "開発   0.068356  0.182960 -0.169479  ...  0.077064 -0.133742  0.037159   \n",
      "テスト  0.370206 -0.188463  0.180798  ...  0.062310 -0.216112 -0.085923   \n",
      "構築  -0.123835 -0.401719 -0.045302  ... -0.204370  0.166554 -0.017961   \n",
      "設計  -0.227307  0.148356  0.002225  ... -0.173117  0.283950  0.178416   \n",
      "\n",
      "           93        94        95        96        97        98        99  \n",
      "担当  -0.172646  0.036667  0.167803 -0.155498 -0.399689  0.398073 -0.133787  \n",
      "開発   0.020709  0.139900 -0.066071  0.195946 -0.158142  0.016426  0.088467  \n",
      "テスト -0.125577  0.214862 -0.019979  0.343186 -0.275925 -0.188157 -0.317357  \n",
      "構築  -0.046654 -0.208086  0.329406  0.101053 -0.457261  0.011707 -0.068731  \n",
      "設計   0.053779  0.043365 -0.184235  0.193474 -0.281724  0.215643 -0.321000  \n",
      "\n",
      "[5 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "# 全単語のベクトルをDataFrameに変換して保存\n",
    "word_vectors_df = pd.DataFrame(\n",
    "    [model.wv[word] for word in model.wv.index_to_key],\n",
    "    index=model.wv.index_to_key\n",
    ")\n",
    "\n",
    "# CSVに保存\n",
    "word_vectors_df.to_csv('../data/external/word_vectors.csv')\n",
    "print(\"\\n単語ベクトルをCSVに保存しました: data/external/word_vectors.csv\")\n",
    "print(f\"形状: {word_vectors_df.shape}\")\n",
    "print(\"\\n最初の5単語:\")\n",
    "print(word_vectors_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73025be0",
   "metadata": {},
   "source": [
    "## ベクトルの図示"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
